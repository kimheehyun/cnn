{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df88c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c79ee",
   "metadata": {},
   "source": [
    "이 코드의 최종 목적은 이미지를 입력받아 10개 클래스 중 하나로 분류하는 CNN(합성곱 신경망)을 만드는 것\n",
    "\n",
    "1) 입력:\n",
    "\n",
    "1채널 흑백 이미지 (예: MNIST 손글씨, 28×28)\n",
    "** 채널이란 이미지에서 색상이나 특징 맵을 구분하는 축. 흑백이미지는 각 필셀이 밝기하나만 가지니까 1채널임. 예를들어 rgb 컬러 이미지는 픽셀마다 빨강, 초록, 파랑 3개의 값이 있어서 3채널임\n",
    "\n",
    "2) 처리 과정:\n",
    "\n",
    "두 번의 합성곱(Convolution) → 두 번의 풀링(MaxPooling) → 완전연결층(Fully Connected) 3개\n",
    "\n",
    "결국 완전 연결층이 분류기 역할이고 합성곱 레이어들은 이미지에서 중유한 패턴을 찾는 전처리기임. \n",
    "\n",
    "활성화 함수(ReLU)로 비선형성 추가\n",
    "\n",
    "3) 출력:\n",
    "\n",
    "크기 (N, 10)인 텐서 (N=배치 크기, 10=클래스 수)\n",
    "\n",
    "각 값은 \"이 이미지가 해당 클래스일 가능성\"을 의미\n",
    "\n",
    "4) 학습 시:\n",
    "\n",
    "실제 라벨과 비교해 손실(Loss) 계산 → 역전파로 가중치 학습\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479edc8",
   "metadata": {},
   "source": [
    "필터(=커널) 란?\n",
    "필터는 이미지에서 특징 패턴을 감지하는 정사각형의 작은 행렬. \n",
    "convolution layer 는 이 필터를 이미지 전체에 슬 . 라 . 이 . 딩 하면서 각 위치마다 하나의 숫자를 만듦.\n",
    "필터 하나가 이미지 전체를 훑고 나면 하나의 출력 채널 (피쳐 맵) 이 만들어짐\n",
    "각 필터는 다른 패턴 ( 뭐 수평선 수직선 점 곡선 등.. ) 에 반응함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6bbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self): #레이어를 정의함. \n",
    "        super(Net, self).__init__()\n",
    "        # kernel\n",
    "        self.conv1=nn.Conv2d(1,6,5) \n",
    "        # 1 : input img channel =>  6: 6개의 필터 / 5: 5*5 convolution ( 필터의 크기 의미)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        # 6 인풋 img 채널 => 16 개의 필터 /  5: 5*5 크기의 필터\n",
    "        \n",
    "        #fc nn.Linear(in_features, out_features) 선형 변환 \n",
    "        # weight 는 (out_features, in_features)\n",
    "        # bias 는 out_features\n",
    "        # y=wx+b\n",
    "        # fc 가 연속적으로 있는 이유?\n",
    "        # 각 fc 는 입력 특징을 다른 차원으로 선형 변환하는데 그 사이사이 ReLU 처럼 비선형성을 넣어주면 모델이 더 복잡(비선형성) 학습 가능함. \n",
    "        #최종 fc3 의 출력 (10) 은 클래스별 점수 (logits) 이고 이를 소프트맥스하여 함께 사용. \n",
    "        self.fc1=nn.Linear(16*5*5,120) #입력 400 을  120 으로 줄임\n",
    "        self.fc2=nn.Linear(120,84) \n",
    "        self.fc3=nn.Linear(84,10) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d59f9",
   "metadata": {},
   "source": [
    "합성곱 출력 크기 계산 공식 (기본):\n",
    "출력크기 = ( 입력크기 - 필터크기 + 2* 패딩 ) / 스트라이드 + 1\n",
    "\n",
    "스트라이드 : 필터 움직이는 간격 ( 1이면 모든 위치에서 연산함. )\n",
    "패딩: 입력 주변에 0으로 둘러싼 픽셀 수 \n",
    "=> 패딩을 하는 이유 : 이미지 가장자리 정보 손실을 막고, 출력 크기 조절하기 위하여 \n",
    "\n",
    "cf) 합성곱의 기본문제: 가장자리 픽셀 정보가 적어짐. \n",
    "필터가 이미지 맨 가장자리 픽셀에 닿을 때 \" 필터 일부는 이미지 밖을 벗어나기 떄문에 그 부분은 연산할 수 없음\" 그래서 가장자리쪽은 내부 픽셀보다 적은 횟수로만 연산에 참여해 정보가 덜 반영."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c1af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "    def forward(self, input):\n",
    "        # convolution layer c1:   self.conv1=nn.Conv2d(1,6,5) \n",
    "        # it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
    "        #배치 사이즈는 보통 데이터를 네트워크에 한꺼번에 넣는 이미지 개수를 의미함. \n",
    "        \n",
    "        \n",
    "        # 첫번째 합성곱 + relu \n",
    "        # 1 채널 이미지가 6개의 필터를 거쳐서 6개의 서로 다른 피쳐맵을 만들어서 출력 텐서 모양은 n, 6, 28, 28 이 됨\n",
    "        c1=F.relu(self,conv1(input))\n",
    "        \n",
    "        #첫 번째 max pooling. 2*2 풀링. -> 크기 절반. \n",
    "        #(N, 6, 14, 14) 중요한 정보만 남기는 것. \n",
    "        s2=F.max_pool2d(c1,(2,2))\n",
    "        \n",
    "        #두번째 합성곱+ reLU\n",
    "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 10, 10) Tensor\n",
    "        #14-5+ 2*0 +1  \n",
    "        c3=F.relu(self.conv2(s2))\n",
    "        \n",
    "        #두번쨰 max pooling\n",
    "        # (N, 16, 10, 10) Tensor -> (N, 16, 5,5)\n",
    "        # 2랑 (2,2) 랑 같음 ㅋ\n",
    "        s4=F.max_pool2d(c3,2)\n",
    "        \n",
    "         # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
    "         #펼치기 : 4차원 텐서를 2차원으로 쭉 펴서 변환해줘야힘. \n",
    "        s4=torch.flatten(s4,1)\n",
    "        # 첫번 째 차원은 그대로 두고 (N, 16,5, 5) => (N,400) 하는거임. \n",
    "        \n",
    "        #완전 연결층\n",
    "        #f5: (N,400) tensor input/ (N,120) Tensor output\n",
    "        # 위 init에 fc1 만들어놓음. \n",
    "        # fc 층은 1차원 벡터 입력 필요. \n",
    "        f5=F.relu(self.fc1(s4)) #400->120\n",
    "        \n",
    "        f6=F.relu(self.fc2(f5)) #120-> 84\n",
    "        \n",
    "        output=self.fc3(f6) #84 -> 10\n",
    "        # ex) 0~9 손글 씨 숫자 \n",
    "         \n",
    "net=Net()\n",
    "print(net) \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc8cc34",
   "metadata": {},
   "source": [
    "fc layer란?\n",
    "뉴런들이 앞층의 모든 뉴러노가 연결되어있는 층\n",
    "입력의 각 요소가 모두 출력의 각 뉴런과 연결 되어이씀.\n",
    "\n",
    "y=wx+b\n",
    "\n",
    "입력 벡터에 가중치 행렬을 곱해서 편향 벡터 더함. \n",
    "\n",
    "왜필요하냐?\n",
    "\n",
    "cnn 에서 합성곱 층은 특징 추출하는 역할을 하는데, \n",
    "완전 연결층은 이 추출된 특징을 분류, 예측 같은 최종 작업에 맞게 변환하는 역할을 함. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
