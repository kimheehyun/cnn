{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8df88c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c79ee",
   "metadata": {},
   "source": [
    "이 코드의 최종 목적은 이미지를 입력받아 10개 클래스 중 하나로 분류하는 CNN(합성곱 신경망)을 만드는 것\n",
    "\n",
    "1) 입력:\n",
    "\n",
    "1채널 흑백 이미지 (예: MNIST 손글씨, 28×28)\n",
    "** 채널이란 이미지에서 색상이나 특징 맵을 구분하는 축. 흑백이미지는 각 필셀이 밝기하나만 가지니까 1채널임. 예를들어 rgb 컬러 이미지는 픽셀마다 빨강, 초록, 파랑 3개의 값이 있어서 3채널임\n",
    "\n",
    "2) 처리 과정:\n",
    "\n",
    "두 번의 합성곱(Convolution) → 두 번의 풀링(MaxPooling) → 완전연결층(Fully Connected) 3개\n",
    "\n",
    "결국 완전 연결층이 분류기 역할이고 합성곱 레이어들은 이미지에서 중유한 패턴을 찾는 전처리기임. \n",
    "\n",
    "활성화 함수(ReLU)로 비선형성 추가\n",
    "\n",
    "3) 출력:\n",
    "\n",
    "크기 (N, 10)인 텐서 (N=배치 크기, 10=클래스 수)\n",
    "\n",
    "각 값은 \"이 이미지가 해당 클래스일 가능성\"을 의미\n",
    "\n",
    "4) 학습 시:\n",
    "\n",
    "실제 라벨과 비교해 손실(Loss) 계산 → 역전파로 가중치 학습\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479edc8",
   "metadata": {},
   "source": [
    "필터(=커널) 란?\n",
    "필터는 이미지에서 특징 패턴을 감지하는 정사각형의 작은 행렬. \n",
    "convolution layer 는 이 필터를 이미지 전체에 슬 . 라 . 이 . 딩 하면서 각 위치마다 하나의 숫자를 만듦.\n",
    "필터 하나가 이미지 전체를 훑고 나면 하나의 출력 채널 (피쳐 맵) 이 만들어짐\n",
    "각 필터는 다른 패턴 ( 뭐 수평선 수직선 점 곡선 등.. ) 에 반응함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a6bbf3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self): #레이어를 정의함. \n",
    "        super(Net, self).__init__()\n",
    "        # kernel\n",
    "        self.conv1=nn.Conv2d(1,6,5) \n",
    "        # 1 : input img channel =>  6: 6개의 필터 / 5: 5*5 convolution ( 필터의 크기 의미)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        # 6 인풋 img 채널 => 16 개의 필터 /  5: 5*5 크기의 필터\n",
    "        \n",
    "        #fc nn.Linear(in_features, out_features) 선형 변환 \n",
    "        # weight 는 (out_features, in_features)\n",
    "        # bias 는 out_features\n",
    "        # y=wx+b\n",
    "        # fc 가 연속적으로 있는 이유?\n",
    "        # 각 fc 는 입력 특징을 다른 차원으로 선형 변환하는데 그 사이사이 ReLU 처럼 비선형성을 넣어주면 모델이 더 복잡(비선형성) 학습 가능함. \n",
    "        #최종 fc3 의 출력 (10) 은 클래스별 점수 (logits) 이고 이를 소프트맥스하여 함께 사용. \n",
    "        self.fc1=nn.Linear(16*5*5,120) #입력 400 을  120 으로 줄임\n",
    "        self.fc2=nn.Linear(120,84) \n",
    "        self.fc3=nn.Linear(84,10) \n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        # convolution layer c1:   self.conv1=nn.Conv2d(1,6,5) \n",
    "        # it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
    "        #배치 사이즈는 보통 데이터를 네트워크에 한꺼번에 넣는 이미지 개수를 의미함. \n",
    "        \n",
    "        \n",
    "        # 첫번째 합성곱 + relu \n",
    "        # 1 채널 이미지가 6개의 필터를 거쳐서 6개의 서로 다른 피쳐맵을 만들어서 출력 텐서 모양은 n, 6, 28, 28 이 됨\n",
    "        c1=F.relu(self.conv1(input))\n",
    "        \n",
    "        #첫 번째 max pooling. 2*2 풀링. -> 크기 절반. \n",
    "        #(N, 6, 14, 14) 중요한 정보만 남기는 것. \n",
    "        s2=F.max_pool2d(c1,(2,2))\n",
    "        \n",
    "        #두번째 합성곱+ reLU\n",
    "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 10, 10) Tensor\n",
    "        #14-5+ 2*0 +1  \n",
    "        c3=F.relu(self.conv2(s2))\n",
    "        \n",
    "        #두번쨰 max pooling\n",
    "        # (N, 16, 10, 10) Tensor -> (N, 16, 5,5)\n",
    "        # 2랑 (2,2) 랑 같음 ㅋ\n",
    "        s4=F.max_pool2d(c3,2)\n",
    "        \n",
    "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
    "        #펼치기 : 4차원 텐서를 2차원으로 쭉 펴서 변환해줘야힘. \n",
    "        s4=torch.flatten(s4,1)\n",
    "        # 첫번 째 차원은 그대로 두고 (N, 16,5, 5) => (N,400) 하는거임. \n",
    "        \n",
    "        #완전 연결층\n",
    "        #f5: (N,400) tensor input/ (N,120) Tensor output\n",
    "        # 위 init에 fc1 만들어놓음. \n",
    "        # fc 층은 1차원 벡터 입력 필요. \n",
    "        f5=F.relu(self.fc1(s4)) #400->120\n",
    "        \n",
    "        f6=F.relu(self.fc2(f5)) #120-> 84\n",
    "        \n",
    "        output=self.fc3(f6) #84 -> 10\n",
    "        # ex) 0~9 손글 씨 숫자 \n",
    "        return output\n",
    "        \n",
    "net=Net()\n",
    "print(net) \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d59f9",
   "metadata": {},
   "source": [
    "합성곱 출력 크기 계산 공식 (기본):\n",
    "출력크기 = ( 입력크기 - 필터크기 + 2* 패딩 ) / 스트라이드 + 1\n",
    "\n",
    "스트라이드 : 필터 움직이는 간격 ( 1이면 모든 위치에서 연산함. )\n",
    "패딩: 입력 주변에 0으로 둘러싼 픽셀 수 \n",
    "=> 패딩을 하는 이유 : 이미지 가장자리 정보 손실을 막고, 출력 크기 조절하기 위하여 \n",
    "\n",
    "cf) 합성곱의 기본문제: 가장자리 픽셀 정보가 적어짐. \n",
    "필터가 이미지 맨 가장자리 픽셀에 닿을 때 \" 필터 일부는 이미지 밖을 벗어나기 떄문에 그 부분은 연산할 수 없음\" 그래서 가장자리쪽은 내부 픽셀보다 적은 횟수로만 연산에 참여해 정보가 덜 반영."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc8cc34",
   "metadata": {},
   "source": [
    "fc layer란?\n",
    "뉴런들이 앞층의 모든 뉴러노가 연결되어있는 층\n",
    "입력의 각 요소가 모두 출력의 각 뉴런과 연결 되어이씀.\n",
    "\n",
    "y=wx+b\n",
    "\n",
    "입력 벡터에 가중치 행렬을 곱해서 편향 벡터 더함. \n",
    "\n",
    "왜필요하냐?\n",
    "\n",
    "cnn 에서 합성곱 층은 특징 추출하는 역할을 하는데, \n",
    "완전 연결층은 이 추출된 특징을 분류, 예측 같은 최종 작업에 맞게 변환하는 역할을 함. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a694d9",
   "metadata": {},
   "source": [
    "net.parameters() 쓰면 그 모델이 학습가능한 텐서가 나옴. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c255b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db91bc",
   "metadata": {},
   "source": [
    "(배치 크기, 채널 수, 높이, 너비) 순서로 크기를 지정한 4차원 텐서 생성\n",
    "\n",
    "torch.randn은 평균 0, 표준편차 1인 정규분포에서 무작위 값을 뽑아요.\n",
    "\n",
    "여기서는:\n",
    "\n",
    "1 → 배치 크기(batch size) = 한 번에 한 장의 이미지만 전달\n",
    "\n",
    "1 → 채널 수 = 흑백 이미지(Gray scale)\n",
    "\n",
    "32, 32 → 이미지 크기 32x32 픽셀\n",
    "\n",
    "즉, 32x32 크기의 흑백 이미지를 1장 무작위로 만든 것이에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3c92f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1104,  0.0589,  0.0333, -0.0351, -0.1095,  0.0660,  0.0238,  0.1284,\n",
      "          0.0514, -0.0174]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)\n",
    "#out은 네트워크가 입력 input에 대해 예측한 결과를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b8c69cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53276a0",
   "metadata": {},
   "source": [
    "Loss Function \n",
    "(output, target)을 input 을 받아서 목표와의 차이를 계산함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4ccb5c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7395, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output=net(input)\n",
    "#타겟은 정답 데이터\n",
    "target=torch.randn(10)\n",
    "target=target.view(1,-1)\n",
    "\n",
    "#손실함수로 mse 사용.\n",
    "criterion=nn.MSELoss()\n",
    "\n",
    "loss=criterion(output,target)\n",
    "\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2707a7",
   "metadata": {},
   "source": [
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> flatten -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19661d9e",
   "metadata": {},
   "source": [
    "pytorch 의 autograd 연산그래프 탐색코드.\n",
    "loss.grad_fn?\n",
    "\n",
    "1) loss 는 텐서임.\n",
    "2) loss는 계산이 어떻게 되었는지 기록하는 함수를 갖고있음.\n",
    "3) grad_fn 은 이 텐서가 어떻게 만들어졌는지 /  계산 그래프의 마지막 함수를 나타내는 속성. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c14cb0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x000001CBDDCF0DF0>\n",
      "<AddmmBackward0 object at 0x000001CBDDCF0070>\n",
      "<AccumulateGrad object at 0x000001CBDDCF0070>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)\n",
    "print(loss.grad_fn.next_functions[0][0]) #LINEAR\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) #RELU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c9175",
   "metadata": {},
   "source": [
    "<MseLossBackward0 object at 0x000001CBDB34A9B0>=> loss 를 만든 연산함수이름  \n",
    "<AddmmBackward0 object at 0x000001CBDDBDF3A0>=> loss 바로 이전 연산 LINEAR 층에서 하는 계싼연산의 backward 함수 객체.  \n",
    "<AccumulateGrad object at 0x000001CBDB34A9B0>=> 그 이전 연산   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9287b94d",
   "metadata": {},
   "source": [
    "backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "449c3bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "tensor([ 0.0050, -0.0069,  0.0086,  0.0071, -0.0030,  0.0080])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70899583",
   "metadata": {},
   "source": [
    "위의 역전파에 따라 weights update. 아래는 simple 한 sgd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "31cf5b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight=weight-learning_rate*gradient\n",
    "learning_rate=0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data*learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647c90e3",
   "metadata": {},
   "source": [
    "다양한 optimizer 를 쓰려면 package 써야됨.  \n",
    "파라미터 업데이트. \n",
    "forward→backward→파라미터 업데이트 루프를 한 번씩 돌리는 게 정상\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7a1b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight changed by:\n",
      "tensor([[[[-2.0929e-04,  4.8667e-05,  1.2733e-05, -2.1085e-05, -1.7181e-05],\n",
      "          [ 2.0564e-06, -4.6909e-05, -2.9013e-05,  1.6853e-04,  7.4327e-05],\n",
      "          [ 8.1271e-05, -1.4084e-05, -6.3166e-05,  1.0383e-04,  1.3530e-05],\n",
      "          [-3.7104e-05,  1.0008e-05,  6.2510e-05, -5.7966e-06,  1.4083e-05],\n",
      "          [ 1.3275e-04, -3.3885e-05, -1.2259e-04, -3.0078e-05,  7.9588e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1796e-04, -3.9125e-06, -5.0887e-06, -8.6412e-05, -1.1364e-04],\n",
      "          [ 3.3513e-05, -6.4969e-06, -3.9786e-06, -7.6085e-05,  1.0831e-04],\n",
      "          [-6.3464e-05,  8.1435e-05, -4.1887e-05,  8.6337e-05,  4.8727e-06],\n",
      "          [ 6.5789e-06, -7.5400e-06,  7.3150e-05, -1.2352e-04,  8.9869e-05],\n",
      "          [-6.6608e-06, -1.2130e-05,  9.4198e-05,  3.0801e-05,  5.5164e-05]]],\n",
      "\n",
      "\n",
      "        [[[-9.9458e-05, -3.2485e-05,  1.2353e-05, -1.9461e-05,  1.1861e-05],\n",
      "          [ 4.3940e-05,  2.9460e-05,  2.9236e-05,  9.6902e-05, -4.2990e-06],\n",
      "          [-2.9773e-05,  1.8205e-04, -2.0835e-04,  8.5220e-05, -7.0572e-05],\n",
      "          [-5.0329e-05,  1.5244e-05,  8.6926e-05, -3.5703e-05,  1.2003e-04],\n",
      "          [-4.8205e-05, -4.6035e-05, -1.4856e-05,  6.2671e-05, -5.2929e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 6.9309e-05, -7.7114e-05,  8.2195e-05, -3.1702e-06,  2.9236e-05],\n",
      "          [-2.4591e-05, -7.3684e-05,  3.1114e-05,  6.6012e-06,  1.3550e-04],\n",
      "          [ 7.8902e-06, -8.3894e-05,  1.6085e-04, -3.4571e-06, -6.3106e-05],\n",
      "          [-6.2898e-05, -6.2631e-05,  1.7139e-04,  2.3976e-05,  1.4931e-04],\n",
      "          [-6.6960e-05, -1.1326e-04,  3.6508e-06,  1.0776e-04, -6.0380e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1897e-04,  5.2154e-05,  3.4692e-05, -2.2650e-06, -6.9905e-05],\n",
      "          [-1.4668e-04,  1.3754e-05,  9.2171e-05, -7.5642e-06,  1.2506e-04],\n",
      "          [ 3.5117e-06, -4.5374e-05, -5.1502e-05,  2.2709e-05, -1.3236e-05],\n",
      "          [ 1.2358e-04,  9.5189e-05, -6.3911e-05,  4.9230e-05,  5.4831e-05],\n",
      "          [-3.7320e-05,  4.6186e-05, -2.6472e-05, -5.3257e-05,  8.9929e-05]]],\n",
      "\n",
      "\n",
      "        [[[-8.0086e-05,  9.8392e-05, -1.4067e-05, -2.2762e-05, -1.2529e-04],\n",
      "          [-6.7651e-06,  5.0813e-06,  1.3493e-05, -9.2974e-05, -2.7120e-06],\n",
      "          [-1.2018e-04, -3.0950e-05,  1.0586e-04,  1.5669e-04,  1.2727e-04],\n",
      "          [ 8.3372e-05, -5.4091e-06, -9.9152e-05, -5.7541e-05,  9.6336e-06],\n",
      "          [-4.5002e-06, -6.0096e-05, -5.6475e-05,  5.7034e-05, -1.0476e-04]]]])\n",
      "conv1.bias changed by:\n",
      "tensor([-2.6189e-06,  2.7746e-05, -1.0988e-04, -5.8338e-05, -2.9802e-06,\n",
      "        -5.8740e-05])\n",
      "conv2.weight changed by:\n",
      "tensor([[[[-5.7526e-05, -1.4275e-05, -4.8671e-05, -8.7075e-05, -4.0419e-05],\n",
      "          [-3.4690e-05, -2.7589e-05, -3.3997e-05, -5.7168e-05, -3.2403e-05],\n",
      "          [-6.8896e-05, -6.1616e-05, -3.3909e-05, -3.5970e-05, -7.3925e-05],\n",
      "          [-3.9585e-05, -2.5164e-05, -5.5950e-05, -3.6003e-05, -1.7114e-05],\n",
      "          [-6.4902e-05, -5.4935e-05, -4.8779e-05, -3.1400e-05, -3.0395e-05]],\n",
      "\n",
      "         [[-5.5538e-05, -3.4269e-05, -7.4888e-05, -4.7406e-05, -2.7020e-05],\n",
      "          [-2.5392e-05, -4.4699e-05, -4.6864e-05, -3.9157e-05, -4.4491e-05],\n",
      "          [-6.2242e-05, -5.0098e-05, -3.7178e-05, -5.2243e-05, -9.2048e-05],\n",
      "          [-5.5715e-05, -1.0456e-05, -3.9943e-05, -4.1299e-05, -5.7977e-05],\n",
      "          [-1.1615e-05, -2.6666e-05, -4.3966e-05, -3.2280e-05, -5.2582e-05]],\n",
      "\n",
      "         [[-1.6268e-05, -3.7234e-05, -1.0284e-04, -6.3583e-05, -5.5470e-05],\n",
      "          [-7.3932e-05, -4.3705e-05, -6.7413e-05, -1.8246e-05, -3.0287e-05],\n",
      "          [-1.4536e-05, -4.3690e-05, -8.4661e-05, -4.5970e-05, -1.9748e-05],\n",
      "          [-7.2457e-05, -7.1667e-05, -4.4111e-05, -3.1509e-05, -4.7133e-05],\n",
      "          [-4.8628e-05, -1.4372e-05, -1.5456e-05, -1.1012e-04, -4.9237e-05]],\n",
      "\n",
      "         [[-9.4184e-05, -9.6720e-05, -4.3266e-05, -3.5990e-05, -6.5550e-05],\n",
      "          [-8.9228e-05, -8.6434e-05, -9.0729e-05, -1.0561e-04, -1.0215e-04],\n",
      "          [-5.7526e-05, -6.0137e-05, -8.9994e-05, -4.2688e-05, -3.1468e-05],\n",
      "          [-6.6712e-05, -6.0886e-05, -9.3095e-05, -9.0070e-05, -7.9554e-05],\n",
      "          [-7.6231e-05, -1.1867e-04, -4.6376e-05, -6.8236e-05, -7.0840e-05]],\n",
      "\n",
      "         [[-5.9344e-05, -5.3206e-05, -2.8718e-05, -4.3252e-05, -6.4306e-05],\n",
      "          [-8.5816e-05, -4.9710e-05, -2.6895e-05, -2.5567e-05, -2.6435e-05],\n",
      "          [-5.3602e-05, -3.8985e-05, -5.9634e-05, -3.1143e-05, -3.0607e-05],\n",
      "          [-4.8526e-05, -2.4624e-05, -4.4368e-05, -3.4563e-05, -3.8065e-05],\n",
      "          [-3.4105e-06, -6.1117e-05, -5.4775e-05, -6.5297e-05, -3.0890e-05]],\n",
      "\n",
      "         [[-3.0436e-05, -9.4771e-06, -2.7809e-05, -1.4854e-05, -3.0112e-05],\n",
      "          [-4.8231e-05, -6.2935e-05, -1.1975e-05, -3.0937e-05, -5.8778e-05],\n",
      "          [-1.8232e-05, -1.2130e-05, -5.0819e-05, -5.0172e-05, -1.0430e-05],\n",
      "          [-3.5703e-05, -5.4717e-05, -2.5563e-05, -3.2496e-05, -2.0079e-05],\n",
      "          [-2.4643e-05, -4.6103e-05, -5.7891e-05, -2.1264e-05, -2.0955e-05]]],\n",
      "\n",
      "\n",
      "        [[[-7.7847e-05, -1.3388e-04, -9.0126e-05, -4.8190e-05, -1.6903e-04],\n",
      "          [-7.8431e-05, -8.6278e-06, -5.2612e-05, -6.9469e-05, -5.5624e-05],\n",
      "          [-1.4753e-04, -1.0791e-04, -1.1581e-04, -7.5374e-05, -7.6871e-06],\n",
      "          [-8.7487e-05, -1.1058e-04, -9.1866e-05, -8.9984e-05, -1.2140e-04],\n",
      "          [-9.5423e-06, -7.0147e-05, -1.0420e-04, -1.1364e-04, -7.9870e-05]],\n",
      "\n",
      "         [[-3.0883e-05, -8.3476e-05, -3.7287e-05, -1.0440e-04, -1.2790e-04],\n",
      "          [-7.9162e-05, -4.2908e-05, -7.7808e-05, -7.8660e-06, -2.1085e-05],\n",
      "          [-6.6265e-05, -1.0947e-04, -5.7839e-05, -6.6541e-05, -2.7008e-05],\n",
      "          [-1.6263e-04, -7.2017e-05, -2.6000e-05, -1.4532e-04, -1.1071e-04],\n",
      "          [-5.1714e-05, -5.1539e-05, -1.0325e-04, -1.1758e-04, -1.2900e-04]],\n",
      "\n",
      "         [[-1.2331e-04, -4.0442e-05, -9.8288e-05, -6.8221e-05, -6.9970e-05],\n",
      "          [-1.0799e-04, -8.8848e-05,  4.3437e-06, -1.0353e-04, -7.7736e-05],\n",
      "          [-4.1556e-05, -4.5080e-05, -1.2496e-04, -4.6045e-05, -4.7995e-05],\n",
      "          [-5.7057e-05, -1.0232e-04, -5.9979e-05, -4.3074e-05, -6.3095e-05],\n",
      "          [-1.7822e-04, -6.1072e-05,  1.1032e-05, -8.2914e-05, -5.6967e-05]],\n",
      "\n",
      "         [[-1.4871e-04, -1.6954e-04, -1.4596e-04, -3.8251e-05, -7.8212e-05],\n",
      "          [-7.4855e-05, -1.2609e-04, -7.7328e-05, -7.7266e-05, -1.0850e-04],\n",
      "          [-1.2746e-04, -1.1069e-04, -3.8121e-05, -1.3270e-04, -1.9778e-04],\n",
      "          [-7.2964e-05, -9.8176e-05, -1.8772e-04, -1.3675e-04, -8.9727e-05],\n",
      "          [-1.1896e-04, -1.3784e-04, -1.0449e-04, -8.9129e-05, -1.0742e-04]],\n",
      "\n",
      "         [[-7.7382e-05, -3.5513e-05, -7.5586e-05, -2.7906e-05, -3.6967e-05],\n",
      "          [-7.1418e-05, -5.4162e-05, -7.4491e-05, -7.7479e-05, -5.7179e-05],\n",
      "          [-6.5014e-05, -6.9162e-05, -1.2467e-04, -8.3487e-05, -1.0599e-04],\n",
      "          [-7.0427e-06, -8.0943e-05, -9.4445e-05, -7.3940e-05, -1.0852e-04],\n",
      "          [-3.9622e-05, -5.6535e-05, -9.6511e-05, -9.8921e-05, -4.9468e-05]],\n",
      "\n",
      "         [[-3.9018e-05, -4.9975e-05, -5.4529e-05, -2.2179e-05, -2.9206e-05],\n",
      "          [-1.2852e-04, -5.5879e-06, -8.6106e-05, -8.3415e-05, -2.9471e-05],\n",
      "          [-4.2537e-05, -1.0654e-04, -3.7380e-05, -1.0236e-04, -7.0386e-05],\n",
      "          [-6.3404e-05, -4.1109e-05, -6.7510e-05, -2.7712e-05, -1.6183e-05],\n",
      "          [-2.2430e-05, -1.1065e-04, -5.1808e-05,  4.4852e-06, -4.5633e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0044e-04,  1.0082e-04,  6.0253e-05,  1.3060e-04,  8.8595e-05],\n",
      "          [ 5.6755e-05,  3.7644e-05,  7.2520e-05,  3.8691e-05,  7.7896e-06],\n",
      "          [ 3.3785e-05,  3.2376e-05,  2.4965e-05,  7.8976e-05,  2.8949e-05],\n",
      "          [ 6.8709e-05,  4.1220e-05,  1.0196e-04,  1.2938e-04,  8.4411e-05],\n",
      "          [ 6.8896e-05,  9.4112e-05,  1.0577e-04,  4.6827e-05,  5.9281e-05]],\n",
      "\n",
      "         [[ 2.6740e-05,  6.1739e-05,  1.8343e-05,  9.6485e-06,  5.6949e-05],\n",
      "          [ 3.1047e-05,  1.2372e-04,  1.8444e-05, -4.1833e-05,  6.6601e-05],\n",
      "          [ 1.1843e-04,  6.4153e-05, -3.7266e-05,  1.5609e-05,  6.1363e-05],\n",
      "          [ 6.9907e-05,  2.4341e-05,  6.2872e-05,  1.2038e-04,  3.0953e-05],\n",
      "          [ 7.6374e-05,  1.6160e-05,  3.9108e-05,  6.2115e-05,  1.1583e-04]],\n",
      "\n",
      "         [[ 1.4035e-04, -1.7457e-05,  9.9710e-05,  4.4394e-05,  7.8812e-05],\n",
      "          [ 5.0175e-05,  1.1009e-04,  8.3178e-05,  7.3064e-05, -4.4148e-05],\n",
      "          [ 7.2483e-05,  1.5112e-04, -3.0808e-05, -7.7337e-06,  1.7808e-04],\n",
      "          [ 1.8042e-05,  8.4193e-05,  1.3521e-04,  3.8553e-05,  1.4424e-05],\n",
      "          [ 5.8457e-05,  6.4328e-05,  2.2590e-05,  1.6084e-04, -2.1990e-05]],\n",
      "\n",
      "         [[ 7.1276e-05,  1.0896e-05,  2.6558e-05,  6.6653e-05,  8.2187e-05],\n",
      "          [ 9.2547e-05,  8.2057e-05,  3.8968e-05,  5.9328e-05,  1.0929e-04],\n",
      "          [-1.5091e-05,  2.2873e-05,  1.4748e-04,  1.2060e-04,  4.3463e-05],\n",
      "          [ 1.6720e-04,  1.0911e-04,  6.9562e-05,  5.4874e-05,  1.4613e-04],\n",
      "          [ 9.7890e-05,  6.3105e-05,  1.4147e-04,  1.1522e-04,  2.6597e-05]],\n",
      "\n",
      "         [[ 7.9402e-05,  1.4562e-05,  1.9304e-05,  7.8119e-05,  1.2031e-04],\n",
      "          [ 9.1407e-05,  7.2081e-05,  6.1579e-06,  8.8934e-05, -1.6019e-07],\n",
      "          [ 2.3782e-05, -2.0131e-05,  2.4177e-05,  9.8623e-05,  7.0145e-05],\n",
      "          [ 8.1211e-07,  7.2159e-06,  1.3303e-04,  8.0913e-06,  8.2223e-05],\n",
      "          [ 4.8086e-05,  2.2955e-05,  5.6563e-05,  9.4738e-05, -8.0629e-06]],\n",
      "\n",
      "         [[ 8.0254e-05,  3.9838e-05, -2.8983e-06,  9.5792e-05,  6.2990e-05],\n",
      "          [ 2.5701e-05,  5.4784e-05,  8.0122e-05,  2.6692e-05,  3.2514e-05],\n",
      "          [ 5.8353e-05,  5.0956e-05,  8.0802e-05,  6.2274e-05,  6.7383e-05],\n",
      "          [ 6.0700e-05,  8.3830e-05,  5.8495e-05,  8.1167e-05, -9.6075e-06],\n",
      "          [ 8.5127e-05,  9.4399e-06,  1.9513e-05,  2.8007e-05,  3.0674e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.7885e-04, -2.4014e-04, -1.1477e-04, -1.3787e-04, -1.8357e-04],\n",
      "          [-6.3136e-05, -1.5994e-04, -1.3155e-04,  5.3942e-06, -1.1142e-04],\n",
      "          [ 6.9663e-06,  6.7092e-06, -3.2999e-05, -1.4315e-04, -1.0991e-04],\n",
      "          [-6.1791e-05, -1.1525e-04, -1.3451e-04, -1.0772e-04, -5.8532e-05],\n",
      "          [-1.5594e-04, -1.2475e-04, -1.0248e-04, -1.3338e-04, -9.8428e-05]],\n",
      "\n",
      "         [[-9.4529e-05, -1.0572e-04, -7.3709e-05, -1.2571e-04, -4.4818e-05],\n",
      "          [-6.7977e-05, -1.9154e-04, -6.9110e-05, -7.5348e-05, -9.7109e-05],\n",
      "          [-1.1192e-04, -3.6860e-05, -6.2056e-05, -6.2599e-05, -1.9252e-05],\n",
      "          [-4.9338e-05, -7.3992e-05, -4.9651e-05, -8.3894e-06, -1.8132e-04],\n",
      "          [-8.6825e-05, -1.2124e-04,  2.9132e-05, -1.4935e-04, -7.0971e-05]],\n",
      "\n",
      "         [[-7.3873e-05, -1.1321e-04, -6.9518e-05, -4.5471e-05, -1.6876e-04],\n",
      "          [-4.5061e-05, -1.5695e-04, -4.6175e-05, -8.9936e-05, -1.5325e-04],\n",
      "          [-3.8804e-05, -1.4815e-04, -3.4838e-05, -1.5115e-04, -6.7607e-05],\n",
      "          [-5.0493e-05, -1.3953e-04, -7.9267e-05, -7.0892e-05, -7.3690e-05],\n",
      "          [-5.3237e-05, -1.2928e-04, -1.0533e-04, -6.3881e-05, -1.1175e-04]],\n",
      "\n",
      "         [[-1.5305e-04, -9.1816e-05, -1.7921e-04, -1.3148e-04, -1.1165e-04],\n",
      "          [-1.1327e-04, -4.3554e-05, -1.7162e-04, -1.4842e-04, -1.0667e-04],\n",
      "          [-1.4076e-04, -9.9935e-05, -1.4020e-04, -1.2935e-04, -1.7418e-04],\n",
      "          [-2.1261e-04, -1.3794e-04, -1.7734e-04, -2.0897e-04, -1.4912e-04],\n",
      "          [-8.2504e-05, -2.4896e-05, -1.4811e-04, -1.7886e-04, -6.2175e-05]],\n",
      "\n",
      "         [[-6.9283e-05, -1.6795e-04, -1.1883e-04, -7.5296e-05, -1.2686e-04],\n",
      "          [-8.6125e-05, -9.8859e-05, -8.6165e-05, -1.3470e-04, -9.2994e-05],\n",
      "          [-1.1798e-05, -8.4609e-05, -2.1778e-05, -7.1913e-05, -9.2093e-05],\n",
      "          [-1.2419e-04, -1.2303e-04, -4.1571e-05, -1.5516e-04, -5.1000e-05],\n",
      "          [-1.4120e-04, -4.2990e-05, -1.6108e-05, -1.3272e-04, -2.7634e-05]],\n",
      "\n",
      "         [[-9.4756e-05, -4.8403e-05, -1.0036e-04, -6.0357e-05, -9.2205e-05],\n",
      "          [-4.8056e-05,  5.8934e-06, -5.1267e-05, -5.6398e-05, -4.5381e-05],\n",
      "          [-8.5223e-05, -8.3365e-05, -3.2675e-05, -1.2364e-04, -3.9682e-05],\n",
      "          [-1.1234e-04, -9.3125e-05, -2.0433e-05, -8.2344e-05, -6.1814e-05],\n",
      "          [-7.2852e-05, -1.0928e-04, -3.5387e-05, -1.0656e-04, -3.3390e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1342e-05,  3.2052e-05,  5.7459e-05,  2.6032e-05,  3.8601e-06],\n",
      "          [-5.7779e-06,  8.5697e-05,  7.5281e-05,  1.5397e-05,  7.7945e-05],\n",
      "          [-1.2040e-05, -5.7928e-06,  5.3305e-05,  5.2862e-06,  3.3010e-05],\n",
      "          [ 5.5901e-05, -1.6446e-05,  1.1608e-05,  3.6966e-05,  1.6637e-05],\n",
      "          [-3.0622e-06,  6.0713e-05,  3.3412e-05, -6.9514e-06,  4.2589e-05]],\n",
      "\n",
      "         [[ 6.1780e-05, -4.4379e-05,  1.5020e-05, -3.2913e-06, -1.6547e-05],\n",
      "          [ 3.3073e-05,  4.4905e-05,  1.7673e-05,  2.9076e-05,  1.9297e-05],\n",
      "          [ 3.3319e-05,  2.1860e-05,  4.3042e-05,  2.9027e-05,  4.0658e-05],\n",
      "          [ 3.2442e-05, -4.7792e-05,  5.0124e-06,  1.4141e-05, -4.1669e-05],\n",
      "          [ 9.2126e-06,  3.9231e-05, -1.1884e-06, -8.2888e-06,  5.4747e-05]],\n",
      "\n",
      "         [[-3.2432e-05,  2.6193e-05,  3.8706e-05, -7.3761e-07,  6.3252e-05],\n",
      "          [ 6.8900e-05,  2.9724e-05,  5.0295e-05,  7.6964e-06,  1.5497e-05],\n",
      "          [ 1.7963e-05,  7.7389e-05, -1.3953e-05,  6.0663e-05,  4.0978e-06],\n",
      "          [ 1.1723e-05,  7.5329e-05,  4.3707e-05,  4.2461e-05,  1.9703e-05],\n",
      "          [-1.8060e-05,  5.6095e-05,  3.9144e-05,  9.6858e-07,  2.0970e-05]],\n",
      "\n",
      "         [[ 1.6507e-05,  5.0791e-05,  8.0835e-05,  4.8365e-05,  8.4260e-05],\n",
      "          [ 1.1735e-05, -1.1332e-05,  9.9510e-05,  5.8757e-05,  6.2265e-05],\n",
      "          [ 6.5956e-05,  3.5375e-05,  7.0460e-05,  1.0610e-05,  1.5914e-05],\n",
      "          [ 2.4706e-05,  7.3798e-05,  3.0668e-06,  2.0966e-05,  7.6801e-05],\n",
      "          [ 4.3659e-05,  5.3920e-05,  4.1924e-05,  8.2679e-05,  4.2744e-05]],\n",
      "\n",
      "         [[-4.3293e-05,  3.8572e-05,  5.4751e-05,  2.6256e-05,  4.1958e-05],\n",
      "          [ 3.5301e-05,  1.2223e-05,  5.4829e-05, -2.0489e-06,  5.5954e-05],\n",
      "          [ 1.9301e-05, -1.9848e-05,  9.1642e-06,  3.2611e-05, -9.6112e-06],\n",
      "          [ 4.6954e-05,  3.2328e-05, -5.2303e-06,  1.3243e-05,  2.1534e-05],\n",
      "          [-2.9131e-05,  4.8012e-05, -1.0896e-07,  1.9431e-05,  5.2787e-05]],\n",
      "\n",
      "         [[ 6.5081e-05,  4.5098e-05,  6.4351e-05,  6.9677e-05,  5.8159e-05],\n",
      "          [ 7.5400e-05, -7.6741e-06, -9.7156e-06,  1.7658e-05, -3.0633e-05],\n",
      "          [ 5.9913e-05, -2.9526e-05,  1.2187e-05,  4.8667e-05, -1.6809e-05],\n",
      "          [ 1.0423e-05,  2.9679e-05, -1.4950e-05, -4.5681e-07,  4.7907e-06],\n",
      "          [ 2.7310e-05,  6.7055e-06,  3.5971e-05,  1.3631e-05,  1.0585e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 6.8210e-06, -3.0389e-05, -1.3422e-05,  3.0696e-05, -6.0064e-05],\n",
      "          [ 1.9535e-05, -4.5725e-05, -3.2820e-05, -5.7638e-05, -5.6162e-05],\n",
      "          [-6.3479e-05, -7.3202e-05, -1.8641e-05, -3.3362e-05, -4.9140e-05],\n",
      "          [-5.5782e-05,  5.1595e-05, -1.1095e-04, -7.6120e-05, -2.6148e-05],\n",
      "          [-3.8948e-05, -2.6442e-05, -9.3505e-07, -6.5507e-06, -2.8960e-05]],\n",
      "\n",
      "         [[-5.0806e-05, -2.4475e-05, -4.3400e-06,  2.2255e-05, -1.1973e-05],\n",
      "          [ 6.7763e-05,  1.9968e-05, -3.4153e-05,  3.7592e-05, -2.6137e-05],\n",
      "          [ 3.3598e-05, -3.3656e-05,  5.0519e-05, -1.4472e-04, -1.2014e-04],\n",
      "          [ 2.7470e-05, -6.5558e-05, -5.4184e-05, -1.9226e-05, -3.6070e-05],\n",
      "          [-3.6068e-05, -7.0719e-05, -2.0608e-05,  1.1079e-05,  4.9174e-07]],\n",
      "\n",
      "         [[ 1.1224e-05, -1.0851e-04, -4.6076e-05, -3.4820e-05, -5.6550e-05],\n",
      "          [-5.4976e-05, -4.8738e-05, -8.8148e-05,  5.3979e-06,  1.6004e-05],\n",
      "          [-7.0416e-05, -5.0496e-05, -7.6566e-05, -3.5293e-05, -1.2495e-05],\n",
      "          [-5.4076e-05, -6.1691e-05, -8.5734e-05, -3.9075e-05, -6.4053e-05],\n",
      "          [-7.1671e-05, -9.0856e-05, -2.9713e-05, -4.6292e-05, -2.7969e-05]],\n",
      "\n",
      "         [[-6.2250e-05, -7.8961e-05, -2.4818e-05, -2.8847e-05, -2.9191e-05],\n",
      "          [-1.5225e-05, -3.7269e-05, -2.6678e-05, -1.2645e-04, -1.5291e-04],\n",
      "          [-6.6793e-05, -8.0921e-05, -1.3152e-04, -5.1808e-05, -2.5824e-05],\n",
      "          [-7.5445e-05, -3.2201e-05,  1.6894e-05, -1.4356e-04, -4.4528e-05],\n",
      "          [-7.4886e-05, -7.6987e-05, -4.3862e-05, -7.7963e-05, -1.2056e-05]],\n",
      "\n",
      "         [[ 1.1496e-05, -2.7277e-05, -2.8607e-05,  6.8755e-06, -2.8387e-05],\n",
      "          [-3.7272e-05, -2.7739e-05,  2.2240e-06, -3.9250e-05, -1.1376e-04],\n",
      "          [-6.6493e-05, -3.3487e-05, -7.9688e-05, -4.7348e-05, -9.1642e-06],\n",
      "          [-1.2717e-04, -8.8550e-06, -2.6142e-05, -5.7183e-05, -1.6760e-05],\n",
      "          [-8.0764e-05,  1.3255e-05, -4.7955e-05, -4.8595e-05, -1.6984e-05]],\n",
      "\n",
      "         [[-7.1421e-05, -1.6000e-05, -2.6159e-05, -6.2786e-05, -2.7344e-06],\n",
      "          [-8.5391e-05, -4.3094e-05, -6.5975e-05, -2.9102e-05, -7.7412e-06],\n",
      "          [-5.4952e-05, -3.2431e-05, -1.1007e-04, -3.7502e-05,  6.1519e-05],\n",
      "          [-1.6984e-05, -2.6796e-05,  1.1269e-06,  4.5259e-05, -1.8650e-05],\n",
      "          [-5.6252e-06, -4.6872e-05, -4.2694e-05, -3.2498e-05, -8.1122e-05]]]])\n",
      "conv2.bias changed by:\n",
      "tensor([-9.9353e-05, -1.5414e-04,  1.1313e-04, -1.0542e-04, -4.8235e-05,\n",
      "        -4.0047e-06, -7.7521e-05, -6.0577e-05, -4.2379e-05, -3.8363e-05,\n",
      "        -1.2070e-06,  5.8796e-05,  1.7072e-04, -1.8548e-04,  5.5082e-05,\n",
      "        -7.4774e-05])\n",
      "fc1.weight changed by:\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-8.8997e-06, -4.2254e-05, -5.2415e-06,  ..., -4.1889e-05,\n",
      "         -7.3150e-05, -7.7724e-05],\n",
      "        [-4.5444e-06, -2.1571e-05, -2.6762e-06,  ..., -2.1387e-05,\n",
      "         -3.7346e-05, -3.9682e-05],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.1548e-07,  5.4762e-07,  6.7987e-08,  ...,  5.4203e-07,\n",
      "          9.4622e-07,  1.0058e-06],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "fc1.bias changed by:\n",
      "tensor([ 0.0000e+00, -9.1530e-05, -4.6730e-05, -1.9415e-04,  1.2320e-04,\n",
      "        -2.4250e-05, -6.5837e-05,  0.0000e+00,  6.5882e-05,  3.6405e-05,\n",
      "        -8.4673e-05, -1.3264e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  9.8786e-05,  7.1555e-05,  2.2389e-04,  7.5158e-05,\n",
      "        -1.1839e-05, -2.8563e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00, -2.3749e-05,  0.0000e+00,  2.3788e-05,\n",
      "        -1.0729e-06,  1.3402e-04,  0.0000e+00,  2.0115e-05,  0.0000e+00,\n",
      "         0.0000e+00, -1.1545e-04,  1.5490e-04,  8.9582e-05, -3.6707e-05,\n",
      "         0.0000e+00, -4.8924e-05,  7.4815e-05, -3.6094e-05, -1.0070e-04,\n",
      "        -2.7749e-05, -1.1133e-04,  0.0000e+00,  8.9746e-05,  6.3893e-05,\n",
      "         0.0000e+00, -1.0470e-04,  9.1109e-05, -2.1537e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  1.3578e-04,  0.0000e+00,  1.0100e-04,\n",
      "         0.0000e+00,  0.0000e+00, -4.5443e-05,  0.0000e+00,  0.0000e+00,\n",
      "         8.5182e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         2.9180e-05,  6.3274e-05, -4.0479e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  7.4841e-06,  0.0000e+00,  0.0000e+00, -2.1198e-04,\n",
      "         7.3984e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.9788e-05,\n",
      "        -1.9906e-05,  0.0000e+00,  0.0000e+00, -4.1479e-05,  0.0000e+00,\n",
      "        -6.6825e-06,  0.0000e+00, -2.5824e-05,  0.0000e+00,  0.0000e+00,\n",
      "         3.0935e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.9256e-05,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0337e-04,\n",
      "         0.0000e+00, -1.5102e-05,  0.0000e+00,  0.0000e+00, -1.7530e-04,\n",
      "        -4.1501e-05,  0.0000e+00,  0.0000e+00,  4.6954e-05,  1.4884e-04,\n",
      "        -1.2823e-04, -1.5268e-05,  0.0000e+00,  1.1865e-06,  0.0000e+00])\n",
      "fc2.weight changed by:\n",
      "tensor([[ 0.0000e+00, -4.6138e-05, -1.7852e-05,  ...,  0.0000e+00,\n",
      "         -1.2554e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00, -9.6306e-05, -3.7260e-05,  ...,  0.0000e+00,\n",
      "         -2.6207e-05,  0.0000e+00],\n",
      "        [ 0.0000e+00, -5.4769e-05, -2.1189e-05,  ...,  0.0000e+00,\n",
      "         -1.4901e-05,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "fc2.bias changed by:\n",
      "tensor([-2.4217e-04, -5.0548e-04, -2.8746e-04,  0.0000e+00,  0.0000e+00,\n",
      "        -2.1604e-04, -1.9261e-04,  0.0000e+00,  2.1437e-04,  5.7015e-04,\n",
      "         6.2209e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00, -1.7745e-04,  0.0000e+00, -3.1758e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  8.7585e-05,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -3.0302e-05,  0.0000e+00,\n",
      "         0.0000e+00,  1.9085e-04,  0.0000e+00, -1.1118e-04,  8.5991e-05,\n",
      "        -8.4223e-05, -4.6343e-04,  0.0000e+00,  1.5027e-04, -5.0661e-04,\n",
      "         0.0000e+00,  1.9273e-04,  0.0000e+00,  4.8436e-05,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  2.7064e-04,  0.0000e+00,  1.8501e-04,\n",
      "        -2.4983e-04,  2.2775e-04,  0.0000e+00,  1.5020e-05,  3.2887e-05,\n",
      "         0.0000e+00, -2.2339e-04,  0.0000e+00,  0.0000e+00, -1.4611e-05,\n",
      "         4.7408e-05,  4.3117e-05, -6.3023e-05, -4.7257e-04,  7.3310e-05,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -4.8967e-04,\n",
      "        -3.9394e-04,  0.0000e+00, -7.5501e-04,  4.7247e-04,  0.0000e+00,\n",
      "        -1.5061e-04,  1.2804e-04,  0.0000e+00,  0.0000e+00, -6.3568e-05,\n",
      "        -3.2789e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00])\n",
      "fc3.weight changed by:\n",
      "tensor([[ 2.2060e-04,  3.3371e-05,  1.3169e-04,  0.0000e+00,  0.0000e+00,\n",
      "          2.0727e-05,  1.6227e-05,  0.0000e+00,  1.9050e-04,  1.7188e-04,\n",
      "          2.7835e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  1.5988e-04,  0.0000e+00,  1.4319e-04,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  1.1715e-04,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  5.4304e-05,  0.0000e+00,\n",
      "          0.0000e+00,  1.5792e-05,  0.0000e+00,  2.2830e-04,  1.6432e-04,\n",
      "          6.0007e-05,  6.8367e-05,  0.0000e+00,  9.8222e-06,  1.2394e-04,\n",
      "          0.0000e+00,  2.9153e-04,  0.0000e+00,  1.8829e-04,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  3.3246e-05,  0.0000e+00,  3.0014e-05,\n",
      "          1.3405e-04,  2.3044e-04,  0.0000e+00,  1.2297e-04,  1.3031e-04,\n",
      "          0.0000e+00,  2.4820e-04,  0.0000e+00,  0.0000e+00,  8.1729e-05,\n",
      "          1.1764e-04,  5.1391e-05,  1.6030e-04,  1.1207e-04,  1.1960e-04,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  2.0379e-04,\n",
      "          7.2690e-06,  0.0000e+00,  9.7577e-05,  3.6530e-05,  0.0000e+00,\n",
      "          2.1895e-04,  1.5152e-04,  0.0000e+00,  0.0000e+00,  1.2152e-04,\n",
      "          1.2399e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.8727e-05,  7.3686e-06,  2.9087e-05,  0.0000e+00,  0.0000e+00,\n",
      "          4.5821e-06,  3.5837e-06,  0.0000e+00,  4.2081e-05,  3.7968e-05,\n",
      "          6.1480e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  3.5316e-05,  0.0000e+00,  3.1630e-05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  2.5878e-05,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1995e-05,  0.0000e+00,\n",
      "          0.0000e+00,  3.4869e-06,  0.0000e+00,  5.0429e-05,  3.6299e-05,\n",
      "          1.3255e-05,  1.5103e-05,  0.0000e+00,  2.1681e-06,  2.7377e-05,\n",
      "          0.0000e+00,  6.4395e-05,  0.0000e+00,  4.1589e-05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  7.3463e-06,  0.0000e+00,  6.6301e-06,\n",
      "          2.9609e-05,  5.0902e-05,  0.0000e+00,  2.7165e-05,  2.8786e-05,\n",
      "          0.0000e+00,  5.4829e-05,  0.0000e+00,  0.0000e+00,  1.8053e-05,\n",
      "          2.5986e-05,  1.1355e-05,  3.5413e-05,  2.4758e-05,  2.6420e-05,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.5016e-05,\n",
      "          1.6056e-06,  0.0000e+00,  2.1555e-05,  8.0690e-06,  0.0000e+00,\n",
      "          4.8365e-05,  3.3470e-05,  0.0000e+00,  0.0000e+00,  2.6844e-05,\n",
      "          2.7388e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.1270e-04,  6.2436e-05,  2.4636e-04,  0.0000e+00,  0.0000e+00,\n",
      "          3.8775e-05,  3.0359e-05,  0.0000e+00,  3.5640e-04,  3.2154e-04,\n",
      "          5.2068e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  2.9910e-04,  0.0000e+00,  2.6787e-04,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  2.1916e-04,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0159e-04,  0.0000e+00,\n",
      "          0.0000e+00,  2.9542e-05,  0.0000e+00,  4.2710e-04,  3.0741e-04,\n",
      "          1.1226e-04,  1.2790e-04,  0.0000e+00,  1.8377e-05,  2.3186e-04,\n",
      "          0.0000e+00,  5.4538e-04,  0.0000e+00,  3.5225e-04,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  6.2197e-05,  0.0000e+00,  5.6148e-05,\n",
      "          2.5078e-04,  4.3110e-04,  0.0000e+00,  2.3005e-04,  2.4379e-04,\n",
      "          0.0000e+00,  4.6434e-04,  0.0000e+00,  0.0000e+00,  1.5290e-04,\n",
      "          2.2008e-04,  9.6142e-05,  2.9989e-04,  2.0967e-04,  2.2374e-04,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.8125e-04,\n",
      "          1.3597e-05,  0.0000e+00,  1.8254e-04,  6.8344e-05,  0.0000e+00,\n",
      "          4.0961e-04,  2.8346e-04,  0.0000e+00,  0.0000e+00,  2.2733e-04,\n",
      "          2.3195e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-5.5547e-04, -8.4035e-05, -3.3159e-04,  0.0000e+00,  0.0000e+00,\n",
      "         -5.2188e-05, -4.0859e-05,  0.0000e+00, -4.7969e-04, -4.3277e-04,\n",
      "         -7.0080e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -4.0257e-04,  0.0000e+00, -3.6054e-04,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -2.9498e-04,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -1.3674e-04,  0.0000e+00,\n",
      "          0.0000e+00, -3.9761e-05,  0.0000e+00, -5.7485e-04, -4.1376e-04,\n",
      "         -1.5110e-04, -1.7215e-04,  0.0000e+00, -2.4732e-05, -3.1208e-04,\n",
      "          0.0000e+00, -7.3406e-04,  0.0000e+00, -4.7411e-04,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -8.3715e-05,  0.0000e+00, -7.5575e-05,\n",
      "         -3.3754e-04, -5.8024e-04,  0.0000e+00, -3.0964e-04, -3.2813e-04,\n",
      "          0.0000e+00, -6.2497e-04,  0.0000e+00,  0.0000e+00, -2.0579e-04,\n",
      "         -2.9622e-04, -1.2940e-04, -4.0364e-04, -2.8220e-04, -3.0115e-04,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -5.1314e-04,\n",
      "         -1.8302e-05,  0.0000e+00, -2.4570e-04, -9.1990e-05,  0.0000e+00,\n",
      "         -5.5131e-04, -3.8153e-04,  0.0000e+00,  0.0000e+00, -3.0598e-04,\n",
      "         -3.1219e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.7135e-05, -4.1053e-06, -1.6198e-05,  0.0000e+00,  0.0000e+00,\n",
      "         -2.5481e-06, -1.9968e-06,  0.0000e+00, -2.3433e-05, -2.1137e-05,\n",
      "         -3.4198e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.9662e-05,  0.0000e+00, -1.7611e-05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -1.4409e-05,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -6.6794e-06,  0.0000e+00,\n",
      "          0.0000e+00, -1.9409e-06,  0.0000e+00, -2.8081e-05, -2.0210e-05,\n",
      "         -7.3807e-06, -8.4094e-06,  0.0000e+00, -1.2070e-06, -1.5244e-05,\n",
      "          0.0000e+00, -3.5860e-05,  0.0000e+00, -2.3159e-05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -4.0904e-06,  0.0000e+00, -3.6918e-06,\n",
      "         -1.6488e-05, -2.8344e-05,  0.0000e+00, -1.5125e-05, -1.6030e-05,\n",
      "          0.0000e+00, -3.0529e-05,  0.0000e+00,  0.0000e+00, -1.0053e-05,\n",
      "         -1.4469e-05, -6.3218e-06, -1.9714e-05, -1.3785e-05, -1.4710e-05,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.5067e-05,\n",
      "         -8.9407e-07,  0.0000e+00, -1.2003e-05, -4.4927e-06,  0.0000e+00,\n",
      "         -2.6932e-05, -1.8638e-05,  0.0000e+00,  0.0000e+00, -1.4947e-05,\n",
      "         -1.5251e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.6672e-05,  5.5488e-06,  2.1890e-05,  0.0000e+00,  0.0000e+00,\n",
      "          3.4459e-06,  2.6976e-06,  0.0000e+00,  3.1672e-05,  2.8573e-05,\n",
      "          4.6268e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  2.6580e-05,  0.0000e+00,  2.3805e-05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  1.9474e-05,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  9.0301e-06,  0.0000e+00,\n",
      "          0.0000e+00,  2.6263e-06,  0.0000e+00,  3.7953e-05,  2.7318e-05,\n",
      "          9.9763e-06,  1.1370e-05,  0.0000e+00,  1.6317e-06,  2.0605e-05,\n",
      "          0.0000e+00,  4.8466e-05,  0.0000e+00,  3.1304e-05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  5.5283e-06,  0.0000e+00,  4.9900e-06,\n",
      "          2.2285e-05,  3.8311e-05,  0.0000e+00,  2.0444e-05,  2.1664e-05,\n",
      "          0.0000e+00,  4.1261e-05,  0.0000e+00,  0.0000e+00,  1.3590e-05,\n",
      "          1.9558e-05,  8.5458e-06,  2.6651e-05,  1.8634e-05,  1.9882e-05,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3878e-05,\n",
      "          1.2070e-06,  0.0000e+00,  1.6220e-05,  6.0722e-06,  0.0000e+00,\n",
      "          3.6399e-05,  2.5190e-05,  0.0000e+00,  0.0000e+00,  2.0201e-05,\n",
      "          2.0608e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.5611e-04, -3.8747e-05, -1.5289e-04,  0.0000e+00,  0.0000e+00,\n",
      "         -2.4065e-05, -1.8840e-05,  0.0000e+00, -2.2117e-04, -1.9954e-04,\n",
      "         -3.2312e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00, -1.8561e-04,  0.0000e+00, -1.6624e-04,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -1.3600e-04,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00, -6.3047e-05,  0.0000e+00,\n",
      "          0.0000e+00, -1.8332e-05,  0.0000e+00, -2.6505e-04, -1.9077e-04,\n",
      "         -6.9667e-05, -7.9375e-05,  0.0000e+00, -1.1403e-05, -1.4389e-04,\n",
      "          0.0000e+00, -3.3845e-04,  0.0000e+00, -2.1860e-04,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00, -3.8601e-05,  0.0000e+00, -3.4846e-05,\n",
      "         -1.5563e-04, -2.6753e-04,  0.0000e+00, -1.4276e-04, -1.5129e-04,\n",
      "          0.0000e+00, -2.8816e-04,  0.0000e+00,  0.0000e+00, -9.4885e-05,\n",
      "         -1.3658e-04, -5.9664e-05, -1.8611e-04, -1.3012e-04, -1.3885e-04,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00, -2.3659e-04,\n",
      "         -8.4387e-06,  0.0000e+00, -1.1329e-04, -4.2416e-05,  0.0000e+00,\n",
      "         -2.5420e-04, -1.7591e-04,  0.0000e+00,  0.0000e+00, -1.4108e-04,\n",
      "         -1.4395e-04,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 4.4182e-06,  6.7055e-07,  2.6375e-06,  0.0000e+00,  0.0000e+00,\n",
      "          4.1723e-07,  3.2410e-07,  0.0000e+00,  3.8184e-06,  3.4422e-06,\n",
      "          5.5786e-07,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  3.2037e-06,  0.0000e+00,  2.8685e-06,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  2.3469e-06,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.0878e-06,  0.0000e+00,\n",
      "          0.0000e+00,  3.1665e-07,  0.0000e+00,  4.5747e-06,  3.2932e-06,\n",
      "          1.1995e-06,  1.3709e-06,  0.0000e+00,  1.9372e-07,  2.4810e-06,\n",
      "          0.0000e+00,  5.8413e-06,  0.0000e+00,  3.7719e-06,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  6.6310e-07,  0.0000e+00,  6.0129e-07,\n",
      "          2.6822e-06,  4.6156e-06,  0.0000e+00,  2.4624e-06,  2.6077e-06,\n",
      "          0.0000e+00,  4.9695e-06,  0.0000e+00,  0.0000e+00,  1.6375e-06,\n",
      "          2.3567e-06,  1.0300e-06,  3.2112e-06,  2.2464e-06,  2.3991e-06,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  4.0829e-06,\n",
      "          1.4529e-07,  0.0000e+00,  1.9521e-06,  7.3202e-07,  0.0000e+00,\n",
      "          4.3884e-06,  3.0361e-06,  0.0000e+00,  0.0000e+00,  2.4363e-06,\n",
      "          2.4840e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 1.3340e-04,  2.0181e-05,  7.9632e-05,  0.0000e+00,  0.0000e+00,\n",
      "          1.2532e-05,  9.8124e-06,  0.0000e+00,  1.1520e-04,  1.0393e-04,\n",
      "          1.6831e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  9.6678e-05,  0.0000e+00,  8.6583e-05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  7.0840e-05,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  3.2835e-05,  0.0000e+00,\n",
      "          0.0000e+00,  9.5479e-06,  0.0000e+00,  1.3805e-04,  9.9365e-05,\n",
      "          3.6286e-05,  4.1343e-05,  0.0000e+00,  5.9390e-06,  7.4945e-05,\n",
      "          0.0000e+00,  1.7628e-04,  0.0000e+00,  1.1386e-04,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  2.0102e-05,  0.0000e+00,  1.8150e-05,\n",
      "          8.1062e-05,  1.3935e-04,  0.0000e+00,  7.4359e-05,  7.8801e-05,\n",
      "          0.0000e+00,  1.5009e-04,  0.0000e+00,  0.0000e+00,  4.9420e-05,\n",
      "          7.1138e-05,  3.1076e-05,  9.6932e-05,  6.7770e-05,  7.2323e-05,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.2323e-04,\n",
      "          4.3958e-06,  0.0000e+00,  5.9005e-05,  2.2091e-05,  0.0000e+00,\n",
      "          1.3240e-04,  9.1627e-05,  0.0000e+00,  0.0000e+00,  7.3485e-05,\n",
      "          7.4975e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 3.4332e-05,  5.1931e-06,  2.0497e-05,  0.0000e+00,  0.0000e+00,\n",
      "          3.2261e-06,  2.5257e-06,  0.0000e+00,  2.9650e-05,  2.6748e-05,\n",
      "          4.3320e-06,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  2.4885e-05,  0.0000e+00,  2.2285e-05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  1.8232e-05,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  8.4522e-06,  0.0000e+00,\n",
      "          0.0000e+00,  2.4587e-06,  0.0000e+00,  3.5534e-05,  2.5578e-05,\n",
      "          9.3393e-06,  1.0639e-05,  0.0000e+00,  1.5274e-06,  1.9290e-05,\n",
      "          0.0000e+00,  4.5374e-05,  0.0000e+00,  2.9303e-05,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  5.1782e-06,  0.0000e+00,  4.6715e-06,\n",
      "          2.0863e-05,  3.5867e-05,  0.0000e+00,  1.9141e-05,  2.0280e-05,\n",
      "          0.0000e+00,  3.8631e-05,  0.0000e+00,  0.0000e+00,  1.2722e-05,\n",
      "          1.8314e-05,  8.0019e-06,  2.4952e-05,  1.7442e-05,  1.8614e-05,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.1719e-05,\n",
      "          1.1325e-06,  0.0000e+00,  1.5186e-05,  5.6848e-06,  0.0000e+00,\n",
      "          3.4078e-05,  2.3581e-05,  0.0000e+00,  0.0000e+00,  1.8913e-05,\n",
      "          1.9297e-05,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n",
      "fc3.bias changed by:\n",
      "tensor([ 1.5159e-03,  3.3487e-04,  2.8360e-03, -3.8171e-03, -1.8647e-04,\n",
      "         2.5202e-04, -1.7600e-03,  3.0369e-05,  9.1669e-04,  2.3595e-04])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer=optim.SGD(net.parameters(),lr=0.01)\n",
    "\n",
    "# in my training loop:\n",
    "optimizer.zero_grad()\n",
    "#역전파 전 기울기 초기화하는거임. 기본적으로 python 은 기존 grad 에 새로운 grad accumulate 함. \n",
    "# 즉 매번 .backward() 호출할 떄마다 누적됨. \n",
    "#so, 매 step 마다 초기화 해줘야 정확한 grad 업뎃 가능.\n",
    "\n",
    "\n",
    "# !!!!!!!!!!1\n",
    "\n",
    "#순전파 (예측값 계산)\n",
    "output=net(input)\n",
    "#손실 계산\n",
    "loss=criterion(output,target)\n",
    "#역전파\n",
    "loss.backward()\n",
    "\n",
    "\n",
    "\n",
    "# 파라미터 복사 (업데이트 전)\n",
    "params_before = {}\n",
    "for name, param in net.named_parameters():\n",
    "    params_before[name] = param.data.clone()\n",
    "\n",
    "# optimizer step (업데이트)!!!!!!!! \n",
    "optimizer.step()\n",
    "\n",
    "# 파라미터 변화 출력z\n",
    "for name, param in net.named_parameters():\n",
    "    diff = param.data - params_before[name]\n",
    "    print(f\"{name} changed by:\")\n",
    "    print(diff)\n",
    "  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
