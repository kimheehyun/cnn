{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df88c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c79ee",
   "metadata": {},
   "source": [
    "이 코드의 최종 목적은 이미지를 입력받아 10개 클래스 중 하나로 분류하는 CNN(합성곱 신경망)을 만드는 것\n",
    "\n",
    "1) 입력:\n",
    "\n",
    "1채널 흑백 이미지 (예: MNIST 손글씨, 28×28)\n",
    "** 채널이란 이미지에서 색상이나 특징 맵을 구분하는 축. 흑백이미지는 각 필셀이 밝기하나만 가지니까 1채널임. 예를들어 rgb 컬러 이미지는 픽셀마다 빨강, 초록, 파랑 3개의 값이 있어서 3채널임\n",
    "\n",
    "2) 처리 과정:\n",
    "\n",
    "두 번의 합성곱(Convolution) → 두 번의 풀링(MaxPooling) → 완전연결층(Fully Connected) 3개\n",
    "\n",
    "결국 완전 연결층이 분류기 역할이고 합성곱 레이어들은 이미지에서 중유한 패턴을 찾는 전처리기임. \n",
    "\n",
    "활성화 함수(ReLU)로 비선형성 추가\n",
    "\n",
    "3) 출력:\n",
    "\n",
    "크기 (N, 10)인 텐서 (N=배치 크기, 10=클래스 수)\n",
    "\n",
    "각 값은 \"이 이미지가 해당 클래스일 가능성\"을 의미\n",
    "\n",
    "4) 학습 시:\n",
    "\n",
    "실제 라벨과 비교해 손실(Loss) 계산 → 역전파로 가중치 학습\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a479edc8",
   "metadata": {},
   "source": [
    "필터(=커널) 란?\n",
    "필터는 이미지에서 특징 패턴을 감지하는 정사각형의 작은 행렬. \n",
    "convolution layer 는 이 필터를 이미지 전체에 슬 . 라 . 이 . 딩 하면서 각 위치마다 하나의 숫자를 만듦.\n",
    "필터 하나가 이미지 전체를 훑고 나면 하나의 출력 채널 (피쳐 맵) 이 만들어짐\n",
    "각 필터는 다른 패턴 ( 뭐 수평선 수직선 점 곡선 등.. ) 에 반응함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6bbf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self): #레이어를 정의함. \n",
    "        super(Net, self).__init__()\n",
    "        # kernel\n",
    "        self.conv1=nn.Conv2d(1,6,5) \n",
    "        # 1 : input img channel =>  6: 6개의 필터 / 5: 5*5 convolution ( 필터의 크기 의미)\n",
    "        self.conv2=nn.Conv2d(6,16,5)\n",
    "        # 6 인풋 img 채널 => 16 개의 필터 /  5: 5*5 크기의 필터\n",
    "        \n",
    "        #fc nn.Linear(in_features, out_features) 선형 변환 \n",
    "        # weight 는 (out_features, in_features)\n",
    "        # bias 는 out_features\n",
    "        # y=wx+b\n",
    "        # fc 가 연속적으로 있는 이유?\n",
    "        # 각 fc 는 입력 특징을 다른 차원으로 선형 변환하는데 그 사이사이 ReLU 처럼 비선형성을 넣어주면 모델이 더 복잡(비선형성) 학습 가능함. \n",
    "        #최종 fc3 의 출력 (10) 은 클래스별 점수 (logits) 이고 이를 소프트맥스하여 함께 사용. \n",
    "        self.fc1=nn.Linear(16*5*5,120) #입력 400 을  120 으로 줄임\n",
    "        self.fc2=nn.Linear(120,84) \n",
    "        self.fc3=nn.Linear(84,10) \n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        # convolution layer c1:   self.conv1=nn.Conv2d(1,6,5) \n",
    "        # it uses RELU activation function, and\n",
    "        # outputs a Tensor with size (N, 6, 28, 28), where N is the size of the batch\n",
    "        #배치 사이즈는 보통 데이터를 네트워크에 한꺼번에 넣는 이미지 개수를 의미함. \n",
    "        \n",
    "        \n",
    "        # 첫번째 합성곱 + relu \n",
    "        # 1 채널 이미지가 6개의 필터를 거쳐서 6개의 서로 다른 피쳐맵을 만들어서 출력 텐서 모양은 n, 6, 28, 28 이 됨\n",
    "        c1=F.relu(self.conv1(input))\n",
    "        \n",
    "        #첫 번째 max pooling. 2*2 풀링. -> 크기 절반. \n",
    "        #(N, 6, 14, 14) 중요한 정보만 남기는 것. \n",
    "        s2=F.max_pool2d(c1,(2,2))\n",
    "        \n",
    "        #두번째 합성곱+ reLU\n",
    "        # Convolution layer C3: 6 input channels, 16 output channels,\n",
    "        # 5x5 square convolution, it uses RELU activation function, and\n",
    "        # outputs a (N, 16, 10, 10) Tensor\n",
    "        #14-5+ 2*0 +1  \n",
    "        c3=F.relu(self.conv2(s2))\n",
    "        \n",
    "        #두번쨰 max pooling\n",
    "        # (N, 16, 10, 10) Tensor -> (N, 16, 5,5)\n",
    "        # 2랑 (2,2) 랑 같음 ㅋ\n",
    "        s4=F.max_pool2d(c3,2)\n",
    "        \n",
    "        # Flatten operation: purely functional, outputs a (N, 400) Tensor\n",
    "        #펼치기 : 4차원 텐서를 2차원으로 쭉 펴서 변환해줘야힘. \n",
    "        s4=torch.flatten(s4,1)\n",
    "        # 첫번 째 차원은 그대로 두고 (N, 16,5, 5) => (N,400) 하는거임. \n",
    "        \n",
    "        #완전 연결층\n",
    "        #f5: (N,400) tensor input/ (N,120) Tensor output\n",
    "        # 위 init에 fc1 만들어놓음. \n",
    "        # fc 층은 1차원 벡터 입력 필요. \n",
    "        f5=F.relu(self.fc1(s4)) #400->120\n",
    "        \n",
    "        f6=F.relu(self.fc2(f5)) #120-> 84\n",
    "        \n",
    "        output=self.fc3(f6) #84 -> 10\n",
    "        # ex) 0~9 손글 씨 숫자 \n",
    "        \n",
    "net=Net()\n",
    "print(net) \n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83d59f9",
   "metadata": {},
   "source": [
    "합성곱 출력 크기 계산 공식 (기본):\n",
    "출력크기 = ( 입력크기 - 필터크기 + 2* 패딩 ) / 스트라이드 + 1\n",
    "\n",
    "스트라이드 : 필터 움직이는 간격 ( 1이면 모든 위치에서 연산함. )\n",
    "패딩: 입력 주변에 0으로 둘러싼 픽셀 수 \n",
    "=> 패딩을 하는 이유 : 이미지 가장자리 정보 손실을 막고, 출력 크기 조절하기 위하여 \n",
    "\n",
    "cf) 합성곱의 기본문제: 가장자리 픽셀 정보가 적어짐. \n",
    "필터가 이미지 맨 가장자리 픽셀에 닿을 때 \" 필터 일부는 이미지 밖을 벗어나기 떄문에 그 부분은 연산할 수 없음\" 그래서 가장자리쪽은 내부 픽셀보다 적은 횟수로만 연산에 참여해 정보가 덜 반영."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c1af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc8cc34",
   "metadata": {},
   "source": [
    "fc layer란?\n",
    "뉴런들이 앞층의 모든 뉴러노가 연결되어있는 층\n",
    "입력의 각 요소가 모두 출력의 각 뉴런과 연결 되어이씀.\n",
    "\n",
    "y=wx+b\n",
    "\n",
    "입력 벡터에 가중치 행렬을 곱해서 편향 벡터 더함. \n",
    "\n",
    "왜필요하냐?\n",
    "\n",
    "cnn 에서 합성곱 층은 특징 추출하는 역할을 하는데, \n",
    "완전 연결층은 이 추출된 특징을 분류, 예측 같은 최종 작업에 맞게 변환하는 역할을 함. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a694d9",
   "metadata": {},
   "source": [
    "net.parameters() 쓰면 그 모델이 학습가능한 텐서가 나옴. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c255b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3db91bc",
   "metadata": {},
   "source": [
    "(배치 크기, 채널 수, 높이, 너비) 순서로 크기를 지정한 4차원 텐서 생성\n",
    "\n",
    "torch.randn은 평균 0, 표준편차 1인 정규분포에서 무작위 값을 뽑아요.\n",
    "\n",
    "여기서는:\n",
    "\n",
    "1 → 배치 크기(batch size) = 한 번에 한 장의 이미지만 전달\n",
    "\n",
    "1 → 채널 수 = 흑백 이미지(Gray scale)\n",
    "\n",
    "32, 32 → 이미지 크기 32x32 픽셀\n",
    "\n",
    "즉, 32x32 크기의 흑백 이미지를 1장 무작위로 만든 것이에요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c92f8a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Module [Net] is missing the required \"forward\" function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n",
      "File \u001b[1;32mc:\\Users\\wibeau\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wibeau\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\wibeau\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:399\u001b[0m, in \u001b[0;36m_forward_unimplemented\u001b[1;34m(self, *input)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_unimplemented\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Define the computation performed at every call.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    Should be overridden by all subclasses.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[38;5;124;03m        registered hooks while the latter silently ignores them.\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] is missing the required \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m function\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    401\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Module [Net] is missing the required \"forward\" function"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
